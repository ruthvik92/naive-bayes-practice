{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa274f36-4c85-4f24-8610-1658a5379ca1",
   "metadata": {},
   "source": [
    "* [Naive-Bayes](https://en.wikipedia.org/wiki/Naive_Bayes_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fbdb708-1dd0-4448-ab11-38abe7b76849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16eea5fc-20a1-4d58-86b2-30866a864769",
   "metadata": {},
   "source": [
    "$p(Y \\mid \\mathbf{x}) = \\frac{p(Y) \\ p(\\mathbf{x} \\mid Y)}{p(\\mathbf{x})} \\propto p(\\mathbf{x} \\mid Y)$   - Eq1\n",
    "\n",
    "\n",
    "$\\underset{k \\in \\{1, \\ldots, K\\}}{\\operatorname{argmax}} \\ p(C_k) \\displaystyle\\prod_{i=1}^n p(x_i \\mid C_k)$  - Eq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b8f6431-249f-4ea3-8244-09f30003911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data using pandas\n",
    "filename = '~/Downloads/diabetes.csv'  # Add the correct file path\n",
    "df = pd.read_csv(filename)\n",
    "mydata = df.values.tolist()\n",
    "\n",
    "# Encode classes and convert attributes to float\n",
    "#mydata = encode_class(mydata)\n",
    "#for i in range(len(mydata)):\n",
    "#    for j in range(len(mydata[i]) - 1):\n",
    "#        mydata[i][j] = float(mydata[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad8332c9-7aca-4fab-927d-01758593b3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac2e143-b5b4-477a-bdb3-bd3f1620417c",
   "metadata": {},
   "source": [
    "# Scikit implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3447f249-e151-4804-93ca-a04bdebd0acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
      "Outcome\n"
     ]
    }
   ],
   "source": [
    "inputs = list(df.keys())[0:-1]\n",
    "print(inputs)\n",
    "output = list(df.keys())[-1]\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "86d7c1cd-2b21-42b3-916d-d712a2c45cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80       151\n",
      "           1       0.62      0.66      0.64        80\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.72      0.73      0.72       231\n",
      "weighted avg       0.75      0.74      0.75       231\n",
      "\n",
      "[[119  32]\n",
      " [ 27  53]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Example dataset\n",
    "X = df[inputs].values.tolist()\n",
    "y = df[output].values.tolist()\n",
    "\n",
    "# Step 1: Preprocessing (example for categorical data encoding)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  # Convert labels to numeric if necessary\n",
    "\n",
    "# Step 2: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 3: Choose and train a Naïve Bayes model\n",
    "# Use Gaussian Naïve Bayes if features are continuous\n",
    "model = GaussianNB()\n",
    "\n",
    "# If you have categorical data, you might use Multinomial or Bernoulli Naïve Bayes\n",
    "# model = MultinomialNB() \n",
    "# model = BernoulliNB()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Make predictions and evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5c60bb4a-7550-4b8a-a322-b18295b7592d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0: {'summaries': [(3.2341040462427744, 3.0436617783563014), (110.56647398843931, 26.61638217874151), (68.04624277456648, 18.589326851687254), (19.378612716763005, 15.033431511049075), (68.40751445086705, 95.2896657940275), (30.219942196531786, 7.820362199040739), (0.4399450867052022, 0.2962485049513914), (31.320809248554912, 11.455191870610197)], 'count': 346}, 1.0: {'summaries': [(4.816753926701571, 3.7067409344218696), (141.3193717277487, 32.4943329734997), (71.66492146596859, 20.192045720742033), (22.31413612565445, 17.770636903620538), (103.92670157068063, 142.27465975917633), (35.33612565445027, 7.141775075303977), (0.5361884816753928, 0.3479684136804108), (36.968586387434556, 11.009042101435623)], 'count': 191}}\n",
      "{0.0: 1.4001382334414657e-15, 1.0: 1.974160575947222e-15}\n",
      "{0.0: 2.5169927639478417e-12, 1.0: 6.499863855587927e-14}\n",
      "{0.0: 4.005555727214499e-13, 1.0: 8.032436433079071e-14}\n",
      "{0.0: 1.5058580913796468e-12, 1.0: 4.595324795791697e-14}\n",
      "{0.0: 2.338911794221136e-13, 1.0: 1.6247025172622194e-14}\n",
      "{0.0: 2.1522844309713078e-13, 1.0: 1.3513499755344635e-14}\n",
      "{0.0: 1.0466004730482381e-12, 1.0: 9.100935845414654e-15}\n",
      "{0.0: 1.0307024223808585e-15, 1.0: 4.259814796921498e-14}\n",
      "{0.0: 1.213862633361139e-16, 1.0: 1.429924331044027e-16}\n",
      "{0.0: 1.7508550935204617e-12, 1.0: 2.6794415434403975e-13}\n",
      "{0.0: 7.434174932132925e-13, 1.0: 1.9453812007969316e-13}\n",
      "{0.0: 9.179117756049171e-13, 1.0: 3.570905352445234e-14}\n",
      "{0.0: 2.22466753872344e-13, 1.0: 1.9179110588662153e-13}\n",
      "{0.0: 1.6693851166028778e-14, 1.0: 1.944913883979931e-14}\n",
      "{0.0: 8.549147434124331e-13, 1.0: 4.429278818924797e-15}\n",
      "{0.0: 4.744292564134807e-13, 1.0: 7.904579631722388e-14}\n",
      "{0.0: 2.917076643457893e-14, 1.0: 2.551724862867738e-13}\n",
      "{0.0: 1.7512044298664507e-13, 1.0: 6.735655275635308e-14}\n",
      "{0.0: 1.0157871641012775e-12, 1.0: 2.7342650200556667e-13}\n",
      "{0.0: 5.73976216628122e-13, 1.0: 2.3655771504521803e-13}\n",
      "{0.0: 5.749869559653176e-19, 1.0: 1.8548810378444374e-22}\n",
      "{0.0: 8.284852127789156e-16, 1.0: 1.154580384262628e-14}\n",
      "{0.0: 1.161588723332399e-16, 1.0: 9.288789113505583e-17}\n",
      "{0.0: 1.9590774935439998e-13, 1.0: 3.615195414175567e-14}\n",
      "{0.0: 3.6020197972574774e-14, 1.0: 9.337986288052437e-14}\n",
      "{0.0: 9.400784469973833e-14, 1.0: 5.260651236653803e-14}\n",
      "{0.0: 8.275471348282098e-13, 1.0: 8.398901166584157e-14}\n",
      "{0.0: 1.3008147716137565e-12, 1.0: 3.2763784855803336e-14}\n",
      "{0.0: 8.803860580159432e-14, 1.0: 6.484331226185377e-14}\n",
      "{0.0: 7.689247619127179e-13, 1.0: 3.4029249640341113e-14}\n",
      "{0.0: 3.401692988580823e-15, 1.0: 1.779878393711851e-15}\n",
      "{0.0: 1.3592450458600606e-13, 1.0: 5.4057449979704114e-14}\n",
      "{0.0: 7.992362596644871e-13, 1.0: 3.256598765784815e-14}\n",
      "{0.0: 1.2434406949952645e-12, 1.0: 7.364534994078429e-14}\n",
      "{0.0: 2.5313724017982484e-12, 1.0: 3.4805761633341847e-13}\n",
      "{0.0: 1.1733272457199272e-16, 1.0: 1.527153709983879e-14}\n",
      "{0.0: 2.2038371049304432e-16, 1.0: 1.9793446114410977e-15}\n",
      "{0.0: 2.6114716772738736e-12, 1.0: 1.096282391504899e-13}\n",
      "{0.0: 9.48497770802668e-13, 1.0: 8.374298387289916e-14}\n",
      "{0.0: 3.3536579750847674e-16, 1.0: 2.06874728404223e-14}\n",
      "{0.0: 6.35243155481372e-13, 1.0: 6.025512090793261e-14}\n",
      "{0.0: 5.027332609302502e-14, 1.0: 1.2806163808088195e-13}\n",
      "{0.0: 1.776708757730022e-12, 1.0: 5.1495326976837223e-14}\n",
      "{0.0: 2.9627570442905624e-12, 1.0: 2.042598368910201e-13}\n",
      "{0.0: 1.1977215822170995e-12, 1.0: 6.770871095512884e-14}\n",
      "{0.0: 2.4057372802258236e-17, 1.0: 3.27114081567343e-15}\n",
      "{0.0: 2.0549411974976502e-14, 1.0: 3.5119821007110325e-14}\n",
      "{0.0: 1.3329705228409017e-12, 1.0: 3.6910924872456757e-13}\n",
      "{0.0: 2.183464750356067e-15, 1.0: 1.226928029342445e-13}\n",
      "{0.0: 1.9033369538234615e-12, 1.0: 1.8511158914293406e-13}\n",
      "{0.0: 2.6964271192321593e-12, 1.0: 6.918090548726458e-14}\n",
      "{0.0: 2.720195039471497e-12, 1.0: 1.964574204216656e-13}\n",
      "{0.0: 2.6114655915563886e-12, 1.0: 6.334000256114434e-13}\n",
      "{0.0: 4.8972236148943396e-18, 1.0: 6.810998994410278e-16}\n",
      "{0.0: 1.0774713364808129e-13, 1.0: 8.412834911402306e-14}\n",
      "{0.0: 1.750205469015844e-13, 1.0: 2.5574301039610634e-14}\n",
      "{0.0: 1.316519158329778e-16, 1.0: 1.0759703315620671e-14}\n",
      "{0.0: 4.8496477661187786e-14, 1.0: 8.810808002890027e-14}\n",
      "{0.0: 1.0483266403207515e-19, 1.0: 1.9360781751698342e-21}\n",
      "{0.0: 7.631190319256219e-16, 1.0: 7.106295105124007e-17}\n",
      "{0.0: 3.2965615090227394e-12, 1.0: 4.681083852799139e-13}\n",
      "{0.0: 1.5900862769753566e-12, 1.0: 5.053329405918858e-14}\n",
      "{0.0: 1.9869604570393124e-12, 1.0: 5.1575937653548634e-14}\n",
      "{0.0: 1.5453507738909703e-13, 1.0: 3.48871972353293e-13}\n",
      "{0.0: 5.522998377430918e-13, 1.0: 4.535134259838013e-14}\n",
      "{0.0: 7.074071802282831e-15, 1.0: 2.8486237292632424e-15}\n",
      "{0.0: 1.2771022566320871e-12, 1.0: 3.64958992487483e-13}\n",
      "{0.0: 2.356587405604387e-13, 1.0: 1.6935460726272077e-14}\n",
      "{0.0: 4.0367232115624095e-13, 1.0: 5.2612761258925206e-14}\n",
      "{0.0: 2.3567785967281563e-14, 1.0: 8.246154204547732e-14}\n",
      "{0.0: 1.3836533201235683e-12, 1.0: 2.056250080966736e-14}\n",
      "{0.0: 9.381661265406978e-13, 1.0: 2.373521540317978e-13}\n",
      "{0.0: 1.6537475883084129e-12, 1.0: 6.564218379601329e-14}\n",
      "{0.0: 5.330173331006998e-16, 1.0: 1.5898902484008327e-15}\n",
      "{0.0: 4.72605353151446e-16, 1.0: 8.169346010769987e-18}\n",
      "{0.0: 1.0970818952791158e-14, 1.0: 2.2212194871371563e-15}\n",
      "{0.0: 1.0643019922351802e-12, 1.0: 2.2343160897100325e-14}\n",
      "{0.0: 1.5544370483476854e-12, 1.0: 2.4920883632658496e-14}\n",
      "{0.0: 1.0794860908872146e-13, 1.0: 2.5093510405941853e-13}\n",
      "{0.0: 2.632744541089548e-13, 1.0: 1.559202033628417e-13}\n",
      "{0.0: 2.4236487860969047e-28, 1.0: 1.334868816429686e-23}\n",
      "{0.0: 7.930482054320231e-13, 1.0: 9.627087013931377e-14}\n",
      "{0.0: 5.343675029909036e-13, 1.0: 9.191132566956577e-14}\n",
      "{0.0: 5.22113361707615e-13, 1.0: 1.1075467132538815e-14}\n",
      "{0.0: 1.1325123952297162e-12, 1.0: 3.7370602693869336e-13}\n",
      "{0.0: 2.4382496885819653e-13, 1.0: 3.690420089533344e-14}\n",
      "{0.0: 3.2559417936170163e-13, 1.0: 1.8109745538465457e-14}\n",
      "{0.0: 1.0699675665214419e-14, 1.0: 1.1331623815919088e-13}\n",
      "{0.0: 1.2418169387966344e-12, 1.0: 7.658250249594898e-14}\n",
      "{0.0: 2.122724924605283e-12, 1.0: 8.560248194031677e-14}\n",
      "{0.0: 1.964216520498841e-12, 1.0: 5.549468569318555e-13}\n",
      "{0.0: 3.8061471720212694e-14, 1.0: 2.2855857379724114e-14}\n",
      "{0.0: 2.2611861601807864e-14, 1.0: 2.5249127601076103e-14}\n",
      "{0.0: 1.0627987605192338e-12, 1.0: 2.0153038276632444e-13}\n",
      "{0.0: 1.855253572597827e-13, 1.0: 2.335004144425121e-13}\n",
      "{0.0: 2.5676051394774664e-12, 1.0: 1.6424048276337733e-13}\n",
      "{0.0: 2.4431990276153785e-12, 1.0: 1.3580920234792834e-13}\n",
      "{0.0: 4.041287587442108e-12, 1.0: 5.289781335635129e-13}\n",
      "{0.0: 1.1469398886160986e-14, 1.0: 6.512324663928204e-14}\n",
      "{0.0: 1.5904052774736111e-12, 1.0: 2.6860443186137522e-14}\n",
      "{0.0: 1.1486337047856256e-12, 1.0: 3.56798510415082e-14}\n",
      "{0.0: 8.671186688163398e-13, 1.0: 2.329573979813971e-13}\n",
      "{0.0: 4.1769115529181864e-14, 1.0: 1.0354550877597231e-14}\n",
      "{0.0: 4.1472933540435714e-14, 1.0: 1.363899187080814e-14}\n",
      "{0.0: 2.0881494580923736e-12, 1.0: 3.672286333863845e-13}\n",
      "{0.0: 9.958768298490802e-13, 1.0: 2.9785735510222636e-13}\n",
      "{0.0: 1.417317573306663e-12, 1.0: 2.171359392352711e-14}\n",
      "{0.0: 1.1817248150819333e-19, 1.0: 6.808783124406691e-22}\n",
      "{0.0: 9.587904264134578e-17, 1.0: 5.2252013226513966e-15}\n",
      "{0.0: 1.266420372409395e-13, 1.0: 2.2660977443579925e-15}\n",
      "{0.0: 4.475664558573286e-13, 1.0: 2.3198451121271107e-15}\n",
      "{0.0: 3.29436261009386e-14, 1.0: 7.300880255375925e-14}\n",
      "{0.0: 8.170907806855933e-16, 1.0: 1.7624314251606121e-16}\n",
      "{0.0: 2.3237167462086967e-12, 1.0: 1.107810886189698e-13}\n",
      "{0.0: 3.8604727583856124e-17, 1.0: 7.704657576509935e-15}\n",
      "{0.0: 1.8714694509085484e-12, 1.0: 2.4933377786801715e-14}\n",
      "{0.0: 1.1939752126071023e-12, 1.0: 3.38589310757679e-14}\n",
      "{0.0: 1.3634637238272157e-12, 1.0: 2.7973351095230802e-14}\n",
      "{0.0: 1.6918948724249886e-14, 1.0: 4.88140179024978e-15}\n",
      "{0.0: 3.14965120847219e-14, 1.0: 1.343798054334047e-13}\n",
      "{0.0: 3.8280395232707677e-13, 1.0: 1.3317918342870574e-13}\n",
      "{0.0: 2.0564236243521026e-13, 1.0: 1.505593784616064e-14}\n",
      "{0.0: 2.760512512152992e-12, 1.0: 6.76378853292245e-13}\n",
      "{0.0: 1.96518647135074e-12, 1.0: 1.480541533465314e-13}\n",
      "{0.0: 2.1254545011564672e-14, 1.0: 2.3186389124672774e-14}\n",
      "{0.0: 1.0828306512326905e-12, 1.0: 2.3017310199003064e-13}\n",
      "{0.0: 1.5091926686553458e-14, 1.0: 1.5565146517644004e-14}\n",
      "{0.0: 1.946658966713273e-15, 1.0: 6.3338283563353255e-15}\n",
      "{0.0: 4.0894502016819136e-13, 1.0: 1.3405088363903019e-13}\n",
      "{0.0: 1.2638459270586936e-15, 1.0: 1.947166175953334e-14}\n",
      "{0.0: 2.8450135012123667e-12, 1.0: 7.598752021274874e-14}\n",
      "{0.0: 1.5630517975734117e-12, 1.0: 3.0955471578288114e-14}\n",
      "{0.0: 1.1262611225707207e-15, 1.0: 2.223630864603245e-15}\n",
      "{0.0: 1.1410396727505893e-17, 1.0: 9.68142013471985e-17}\n",
      "{0.0: 2.2581207328172394e-12, 1.0: 4.369217860722152e-14}\n",
      "{0.0: 7.406081611055261e-13, 1.0: 4.2393230853102925e-14}\n",
      "{0.0: 1.8245651855092354e-18, 1.0: 1.7595325708824478e-15}\n",
      "{0.0: 1.7271788824194105e-12, 1.0: 1.149831453688204e-13}\n",
      "{0.0: 9.268824619661276e-15, 1.0: 7.242436082163149e-14}\n",
      "{0.0: 6.977822360796624e-14, 1.0: 6.210290861505585e-14}\n",
      "{0.0: 1.4206141059469204e-12, 1.0: 2.257307968762269e-13}\n",
      "{0.0: 1.011871158293775e-13, 1.0: 5.978285195936024e-15}\n",
      "{0.0: 1.423376367134871e-16, 1.0: 2.3336694466343183e-14}\n",
      "{0.0: 1.1161830936697175e-14, 1.0: 2.0666422122283262e-13}\n",
      "{0.0: 1.4543550817786656e-13, 1.0: 4.907728734326529e-14}\n",
      "{0.0: 3.938587255190799e-13, 1.0: 3.037944873355728e-14}\n",
      "{0.0: 1.8143858696257307e-13, 1.0: 1.4615678900082493e-13}\n",
      "{0.0: 2.656292537744878e-14, 1.0: 2.292684311091193e-13}\n",
      "{0.0: 1.193573925333126e-13, 1.0: 6.3083312021099594e-15}\n",
      "{0.0: 7.861790606107035e-13, 1.0: 2.7351833449292043e-14}\n",
      "{0.0: 2.285355446380997e-13, 1.0: 2.288334350174606e-13}\n",
      "{0.0: 3.6235607382264505e-15, 1.0: 9.523726909694302e-15}\n",
      "{0.0: 1.0775690924695342e-14, 1.0: 8.918958707433223e-15}\n",
      "{0.0: 1.088777956640018e-12, 1.0: 2.2735387214008834e-13}\n",
      "{0.0: 1.168231735900275e-12, 1.0: 9.750944310216602e-14}\n",
      "{0.0: 1.3710149340551472e-12, 1.0: 1.8171546781559596e-14}\n",
      "{0.0: 5.695246362818315e-15, 1.0: 5.6442519956299825e-15}\n",
      "{0.0: 2.892438895812649e-14, 1.0: 1.082156693681933e-14}\n",
      "{0.0: 8.046024397898175e-13, 1.0: 3.829651622911263e-13}\n",
      "{0.0: 1.7641252038581292e-12, 1.0: 2.2700361920869336e-14}\n",
      "{0.0: 2.945164326889981e-14, 1.0: 3.27037296109109e-13}\n",
      "{0.0: 2.3003744984929247e-19, 1.0: 6.699067684906375e-23}\n",
      "{0.0: 1.0386683744328918e-14, 1.0: 5.180646972260893e-14}\n",
      "{0.0: 1.7249444166943627e-12, 1.0: 2.6867486994988267e-13}\n",
      "{0.0: 5.891255871965227e-13, 1.0: 2.3141447587759508e-14}\n",
      "{0.0: 5.557544671901656e-13, 1.0: 1.1438473770372374e-13}\n",
      "{0.0: 1.2945312587623108e-12, 1.0: 3.4518071947655317e-13}\n",
      "{0.0: 5.456799653162477e-13, 1.0: 7.571133152839688e-15}\n",
      "{0.0: 1.4959177485209735e-13, 1.0: 4.594690082770119e-14}\n",
      "{0.0: 3.648871460220034e-25, 1.0: 1.1813216327443525e-19}\n",
      "{0.0: 5.961035569676316e-13, 1.0: 5.5123002862135846e-14}\n",
      "{0.0: 1.7523677134377538e-15, 1.0: 1.2133350966607794e-16}\n",
      "{0.0: 6.960399307886864e-17, 1.0: 1.399200748607546e-16}\n",
      "{0.0: 1.4087110737564406e-12, 1.0: 3.193670626905746e-14}\n",
      "{0.0: 5.723270786698882e-13, 1.0: 8.646138782216102e-15}\n",
      "{0.0: 1.9084783507518298e-14, 1.0: 3.053292265757731e-14}\n",
      "{0.0: 1.4211441899068891e-12, 1.0: 1.1429267465180014e-13}\n",
      "{0.0: 2.5411068529722805e-15, 1.0: 2.936766625153351e-14}\n",
      "{0.0: 1.709729635848786e-13, 1.0: 1.6157072643058214e-13}\n",
      "{0.0: 1.313773129299638e-13, 1.0: 1.2986233669065544e-13}\n",
      "{0.0: 1.0770610235520346e-15, 1.0: 8.021979877327168e-15}\n",
      "{0.0: 3.0035870848439764e-15, 1.0: 9.677646286360359e-15}\n",
      "{0.0: 1.9229653267831402e-13, 1.0: 1.7969533352963752e-14}\n",
      "{0.0: 7.802473754038824e-13, 1.0: 6.1399272050699965e-15}\n",
      "{0.0: 3.222207923977436e-15, 1.0: 8.200604170658009e-15}\n",
      "{0.0: 1.3819873089455543e-12, 1.0: 1.6102164329517268e-13}\n",
      "{0.0: 7.176142260419698e-13, 1.0: 7.780923422649355e-14}\n",
      "{0.0: 6.944737374410216e-13, 1.0: 5.439875979196819e-14}\n",
      "{0.0: 3.306542658364261e-14, 1.0: 2.187842567077936e-14}\n",
      "{0.0: 7.693280719445098e-19, 1.0: 8.425170723124075e-16}\n",
      "{0.0: 7.974319770149544e-19, 1.0: 9.8899638608672e-16}\n",
      "{0.0: 2.1225137431715644e-13, 1.0: 1.5608130385547965e-14}\n",
      "{0.0: 2.690131127301923e-12, 1.0: 3.3947102072461034e-14}\n",
      "{0.0: 6.681699518715621e-20, 1.0: 3.5070090185807336e-16}\n",
      "{0.0: 1.2176105186807707e-12, 1.0: 6.350245731683148e-14}\n",
      "{0.0: 2.909552556044336e-12, 1.0: 7.338634613198244e-14}\n",
      "{0.0: 1.0596539252819554e-12, 1.0: 3.1186741917255026e-14}\n",
      "{0.0: 2.709443772446441e-13, 1.0: 2.7862914294965183e-14}\n",
      "{0.0: 5.279544419163306e-14, 1.0: 2.635995742795672e-13}\n",
      "{0.0: 3.608857178292191e-17, 1.0: 7.57941474625258e-17}\n",
      "{0.0: 8.422749103075125e-13, 1.0: 2.8842856994392426e-14}\n",
      "{0.0: 6.367716234683426e-13, 1.0: 1.2780084627106965e-13}\n",
      "{0.0: 2.1541844486035854e-13, 1.0: 2.6649229271900946e-13}\n",
      "{0.0: 3.4795246732418625e-13, 1.0: 6.745445816131029e-14}\n",
      "{0.0: 4.340868876514807e-13, 1.0: 6.931321127804751e-14}\n",
      "{0.0: 1.9807954637185295e-12, 1.0: 9.344645374931046e-14}\n",
      "{0.0: 1.8925949186964355e-12, 1.0: 1.90904454707271e-14}\n",
      "{0.0: 7.103512201567909e-15, 1.0: 3.235374567726769e-14}\n",
      "{0.0: 1.649423508979446e-12, 1.0: 2.4980131054603405e-14}\n",
      "{0.0: 3.116372851165222e-13, 1.0: 4.8159213038973184e-14}\n",
      "{0.0: 8.073296465718998e-14, 1.0: 9.191685522230437e-14}\n",
      "{0.0: 3.543600315026117e-14, 1.0: 1.837750119345655e-13}\n",
      "{0.0: 1.083782325192109e-14, 1.0: 3.7083135823733166e-14}\n",
      "{0.0: 2.538252170286681e-13, 1.0: 5.774126976872393e-13}\n",
      "{0.0: 1.2381841108812055e-13, 1.0: 6.815998250005002e-14}\n",
      "{0.0: 1.751050883312616e-12, 1.0: 1.8940388319840882e-14}\n",
      "{0.0: 1.5889185790933736e-12, 1.0: 3.122415895623002e-14}\n",
      "{0.0: 4.761697934798417e-17, 1.0: 1.4999240873392657e-16}\n",
      "{0.0: 1.998844816147438e-12, 1.0: 4.452280256703046e-14}\n",
      "{0.0: 3.694981986754291e-15, 1.0: 1.092826406196333e-14}\n",
      "{0.0: 5.374116903470984e-13, 1.0: 1.6824151325053879e-13}\n",
      "{0.0: 1.6087235378565465e-13, 1.0: 2.183993031588006e-14}\n",
      "{0.0: 1.2421027626287184e-13, 1.0: 3.7121574842811074e-13}\n",
      "{0.0: 2.613515638942824e-12, 1.0: 1.0577969023675707e-13}\n",
      "{0.0: 1.9441210331828572e-34, 1.0: 1.1491114984778997e-23}\n",
      "{0.0: 1.7272759035107108e-13, 1.0: 5.931724708219406e-14}\n",
      "{0.0: 1.6831020643939632e-13, 1.0: 3.26913672613289e-13}\n",
      "{0.0: 5.726805931953669e-17, 1.0: 2.064190790924959e-15}\n",
      "{0.0: 2.1423898318273044e-13, 1.0: 2.1812744362062826e-13}\n",
      "{0.0: 1.1919947136890005e-13, 1.0: 3.8784866992240174e-13}\n",
      "{0.0: 1.36672156721108e-12, 1.0: 8.433313351729499e-14}\n",
      "Train Size: 537\n",
      "Test Size: 231\n",
      "Actual:      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0]\n",
      "Predictions: [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]\n",
      "Accuracy: 79.22%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # -----------------------------\n",
    "# # 1) Dataset\n",
    "# # -----------------------------\n",
    "# mydata = [\n",
    "#     [6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0, 1.0],\n",
    "#     [1.0, 85.0, 66.0, 29.0, 0.0, 26.6, 0.351, 31.0, 0.0],\n",
    "#     [8.0, 183.0, 64.0, 0.0, 0.0, 23.3, 0.672, 32.0, 1.0],\n",
    "#     [1.0, 89.0, 66.0, 23.0, 94.0, 28.1, 0.167, 21.0, 0.0],\n",
    "#     [0.0, 137.0, 40.0, 35.0, 168.0, 43.1, 2.288, 33.0, 1.0]\n",
    "# ]\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Helper functions\n",
    "# -----------------------------\n",
    "def train_test_split(dataset, test_size=0.4, seed=42):\n",
    "    \"\"\"\n",
    "    Splits dataset into train and test sets based on test_size ratio.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    data_copy = dataset[:]\n",
    "    random.shuffle(data_copy)\n",
    "    split_index = int(len(data_copy) * (1 - test_size))\n",
    "    return data_copy[:split_index], data_copy[split_index:]\n",
    "\n",
    "def separate_by_class(dataset):\n",
    "    \"\"\"\n",
    "    Splits the dataset into a dictionary keyed by class value (0 or 1),\n",
    "    each containing only those rows.\n",
    "    \"\"\"\n",
    "    separated = {}\n",
    "    for row in dataset:\n",
    "        class_value = row[-1]\n",
    "        if class_value not in separated:\n",
    "            separated[class_value] = []\n",
    "        separated[class_value].append(row)\n",
    "    return separated\n",
    "\n",
    "def mean(values):\n",
    "    return sum(values) / float(len(values))\n",
    "\n",
    "def stdev(values):\n",
    "    \"\"\"\n",
    "    Compute the standard deviation of a list of numbers.\n",
    "    Use (N-1) in the denominator to match sample stdev (unbiased).\n",
    "    \"\"\"\n",
    "    avg = mean(values)\n",
    "    variance = sum([(x - avg)**2 for x in values]) / (len(values) - 1)\n",
    "    return math.sqrt(variance) if len(values) > 1 else 0.0\n",
    "\n",
    "def summarize_dataset(dataset):\n",
    "    \"\"\"\n",
    "    For each attribute (column) in the dataset (except the last, which is the label),\n",
    "    calculate the mean and standard deviation.\n",
    "    Returns a list of (mean, stdev) tuples for each column.\n",
    "    \"\"\"\n",
    "    summaries = []\n",
    "    # Exclude the label column at the end\n",
    "    num_features = len(dataset[0]) - 1  \n",
    "    for col in range(num_features):\n",
    "        column_values = [row[col] for row in dataset]\n",
    "        col_mean = mean(column_values)\n",
    "        col_stdev = stdev(column_values)\n",
    "        summaries.append((col_mean, col_stdev))\n",
    "    return summaries\n",
    "\n",
    "def summarize_by_class(dataset):\n",
    "    \"\"\"\n",
    "    Splits dataset by class, then computes the summary stats for each class separately.\n",
    "    Returns a dict of class_value -> list of (mean, stdev) for each feature.\n",
    "    \"\"\"\n",
    "    separated = separate_by_class(dataset)\n",
    "    summaries = {}\n",
    "    for class_value, rows in separated.items():\n",
    "        summaries[class_value] = summarize_dataset(rows)\n",
    "    return summaries\n",
    "\n",
    "def calculate_gaussian_probability(x, mean, stdev):\n",
    "    \"\"\"\n",
    "    Calculate the probability of 'x' for a normal distribution with the given mean and stdev.\n",
    "    \"\"\"\n",
    "    if stdev == 0:\n",
    "        # To handle the case of stdev=0, we can return 1 if x == mean, else a very small number.\n",
    "        return 1.0 if x == mean else 1e-9\n",
    "    \n",
    "    exponent = math.exp(-((x - mean)**2 / (2 * stdev**2)))\n",
    "    return (1 / (math.sqrt(2 * math.pi) * stdev)) * exponent\n",
    "\n",
    "def calculate_class_probabilities(summaries, row):\n",
    "    \"\"\"\n",
    "    Given a row (of features), compute the posterior probability for each class\n",
    "    using the precomputed summaries (mean, stdev) for each feature of each class.\n",
    "    \"\"\"\n",
    "    total_rows = 0\n",
    "    for class_value, class_summaries in summaries.items():\n",
    "        total_rows += len(class_summaries)  # Incorrect: We need the row count, not columns count\n",
    "    # Correction: total_rows should be the sum of the number of data rows for each class\n",
    "    # But we actually need the prior probability from the original dataset counts.\n",
    "    # Let's keep track of class_counts separately. We can store it in 'summaries' or compute on the fly.\n",
    "\n",
    "    # Alternatively, we can store a separate structure for prior probabilities. \n",
    "    # For simplicity, let's store them in 'class_counts' once we know how many data points belong to each class.\n",
    "    pass\n",
    "\n",
    "# To handle prior probabilities properly, let's rewrite `summarize_by_class` to also return class_counts:\n",
    "def summarize_by_class_with_counts(dataset):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    {\n",
    "      class_value: {\n",
    "         'summaries': [(mean1, stdev1), (mean2, stdev2), ...],\n",
    "         'count': number_of_rows_in_this_class\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    "    separated = separate_by_class(dataset)\n",
    "    summaries = {}\n",
    "    for class_value, rows in separated.items():\n",
    "        summaries[class_value] = {\n",
    "            'summaries': summarize_dataset(rows),\n",
    "            'count': len(rows)\n",
    "        }\n",
    "    return summaries\n",
    "\n",
    "def calculate_class_probabilities(summaries, row, total_rows):\n",
    "    \"\"\"\n",
    "    Calculate P(class|data) for each class (not strictly normalized).\n",
    "    We'll compare the relative probabilities.\n",
    "    \"\"\"\n",
    "    probabilities = {}\n",
    "    \n",
    "    for class_value, class_info in summaries.items(): #iterates for 2 times\n",
    "        # Prior probability P(class)\n",
    "        class_count = class_info['count']\n",
    "        p_class = class_count / float(total_rows)\n",
    "        \n",
    "        probabilities[class_value] = p_class  # start with prior in Eq2 P(C_k)\n",
    "\n",
    "        # Likelihood for each feature\n",
    "        # in Eq2 P(X1|C1) x P(X2|C1) x P(X3|C1) ...x P(X8|C1) 1st loop\n",
    "        # in Eq2 P(X1|C2) x P(X2|C2) x P(X3|C2) ...x P(X8|C2) 2nd loop\n",
    "        for i, (mean_i, stdev_i) in enumerate(class_info['summaries']): #iterates for 8 times\n",
    "            x = row[i]\n",
    "            p_x_given_class = calculate_gaussian_probability(x, mean_i, stdev_i)\n",
    "            probabilities[class_value] *= p_x_given_class  \n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "def predict(summaries, row, total_rows):\n",
    "    \"\"\"\n",
    "    Given a row, compute the posterior probability for each class and\n",
    "    return the class with the highest probability.\n",
    "    \"\"\"\n",
    "    probabilities = calculate_class_probabilities(summaries, row, total_rows)\n",
    "    print(probabilities)\n",
    "    best_label, best_prob = None, -1\n",
    "    for class_value, probability in probabilities.items():\n",
    "        if best_label is None or probability > best_prob:\n",
    "            best_prob = probability\n",
    "            best_label = class_value\n",
    "    return best_label\n",
    "\n",
    "def get_predictions(summaries, test, total_rows):\n",
    "    \"\"\"\n",
    "    Predict each row in the test set.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    for row in test:\n",
    "        output = predict(summaries, row, total_rows)\n",
    "        predictions.append(output)\n",
    "    return predictions\n",
    "\n",
    "def accuracy_metric(actual, predicted):\n",
    "    \"\"\"\n",
    "    Compute the accuracy as (number correct / total) * 100.\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return (correct / float(len(actual))) * 100.0\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Putting it all together\n",
    "# -----------------------------\n",
    "def naive_bayes_train_test(dataset, test_ratio=0.4):\n",
    "    # 1) Split into train/test\n",
    "    train, test = train_test_split(dataset, test_size=test_ratio)\n",
    "\n",
    "    # 2) Summarize training dataset\n",
    "    #    (this will give means, stdevs per feature per class + class counts)\n",
    "    summaries = summarize_by_class_with_counts(train)\n",
    "    print(summaries)\n",
    "\n",
    "    # 3) Make predictions on test dataset\n",
    "    total_rows_in_train = len(train)  # used for prior probabilities\n",
    "    predictions = []\n",
    "    actual = []\n",
    "    for row in test:\n",
    "        # The last column is the actual label\n",
    "        actual_label = row[-1]\n",
    "        actual.append(actual_label)\n",
    "\n",
    "        # Predict\n",
    "        predicted_label = predict(summaries, row, total_rows_in_train)\n",
    "        predictions.append(predicted_label)\n",
    "    \n",
    "    # 4) Calculate accuracy\n",
    "    acc = accuracy_metric(actual, predictions)\n",
    "\n",
    "    return {\n",
    "        'train_size': len(train),\n",
    "        'test_size': len(test),\n",
    "        'predictions': predictions,\n",
    "        'actual': actual,\n",
    "        'accuracy': acc\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Run the classifier on the sample data\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    results = naive_bayes_train_test(mydata, test_ratio=0.3)\n",
    "    print(\"Train Size:\", results['train_size'])\n",
    "    print(\"Test Size:\", results['test_size'])\n",
    "    print(\"Actual:     \", results['actual'])\n",
    "    print(\"Predictions:\", results['predictions'])\n",
    "    print(f\"Accuracy: {results['accuracy']:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8e286d-7cc6-4a91-b759-eaeed8ae4452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
